{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "#from matplotlib import pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(file):\n",
    "    df = pd.read_csv(file, parse_dates=True, index_col=0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_eval(y_pred, dtrain):\n",
    "    y_true = dtrain.get_label()\n",
    "    err = f1_score(y_true, np.round(y_pred))\n",
    "    return 'f1_err', err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_confusion_matrix(tn, fp, fn, tp):\n",
    "    print(\"    \",\"True\", \"False\")\n",
    "    print(\"True \", \" \", tp, \"  \", fp)\n",
    "    print(\"False\", \" \",fn,\"  \", tn)\n",
    "    print(\"_______________________________________\")\n",
    "    print(\"---------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_______________________________________\n",
      "______________Training_________________\n",
      "F1 score 0.9697766097240472\n",
      "     True False\n",
      "True    369    20\n",
      "False   3    390\n",
      "_______________________________________\n",
      "---------------------------------------\n",
      "_______________Testing_________________\n",
      "F1 score nan\n",
      "     True False\n",
      "True    0    0\n",
      "False   65    207\n",
      "_______________________________________\n",
      "---------------------------------------\n",
      "---------------------------------------\n"
     ]
    }
   ],
   "source": [
    "X_train = read_csv('output/\\CompleteIndexesWeeklyTrainDecompKalman_0.csv')\n",
    "X_test = read_csv('output/\\CompleteIndexesWeeklyTestDecompKalman_0.csv')\n",
    "X_train = X_train.reindex(sorted(X_train.columns), axis=1)\n",
    "X_test = X_test.reindex(sorted(X_test.columns), axis=1)['2015-01-02':'2020-03-13']\n",
    "\n",
    "y = pd.read_csv('input/\\sp500_target_regimes.csv', parse_dates=True)\n",
    "y.index = y['date'].values\n",
    "y = y[['regime']]\n",
    "y = y['regime']=='BEAR'\n",
    "y = pd.DataFrame (y, columns = ['regime'])\n",
    "\n",
    "y_train = y.loc['2000-01-01':'2015-01-01']\n",
    "y_test = y.loc['2015-01-02':]\n",
    "\n",
    "best_params = {'colsample_bytree': 0.8, \n",
    "               'gamma': 5, \n",
    "               'learning_rate': 0.0001, \n",
    "               'max_delta_step': 1, \n",
    "               'max_depth': 1, \n",
    "               'min_child_weight': 2, \n",
    "               'n_estimators': 65, \n",
    "               'reg_alpha': 1e-05, \n",
    "               'scale_pos_weight': 5, \n",
    "               'subsample': 0.8}\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(objective=\"binary:logistic\",\n",
    "                                  eval_metric = 'auc',\n",
    "                                  learning_rate=best_params['learning_rate'], \n",
    "                                  n_estimators=best_params['n_estimators'], \n",
    "                                  min_child_weight=best_params['min_child_weight'], \n",
    "                                  gamma=best_params['gamma'],\n",
    "                                  max_delta_step=best_params['max_delta_step'],\n",
    "                                  max_depth=best_params['max_depth'],\n",
    "                                  subsample=best_params['subsample'],\n",
    "                                  scale_pos_weight=best_params['scale_pos_weight'],\n",
    "                                  colsample_bytree=best_params['colsample_bytree'],\n",
    "                                  reg_alpha=best_params['reg_alpha']\n",
    "                              )\n",
    "model = xgb_model.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = model.predict(X_train)\n",
    "print(\"_______________________________________\")\n",
    "print(\"______________Training_________________\")\n",
    "tn, fp, fn, tp = confusion_matrix(y_train, y_train_pred).ravel()\n",
    "precision = tp/(tp+fp)\n",
    "recall = tp/(tp+fn)\n",
    "f_score = 2*precision*recall/(precision+recall)  \n",
    "print(\"F1 score\", f_score)\n",
    "print_confusion_matrix(tn, fp, fn, tp)\n",
    "print(\"_______________Testing_________________\")\n",
    "y_pred = model.predict(X_test)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "precision = tp/(tp+fp)\n",
    "recall = tp/(tp+fn)\n",
    "f_score = 2*precision*recall/(precision+recall)\n",
    "print(\"F1 score\", f_score)\n",
    "print_confusion_matrix(tn, fp, fn, tp)\n",
    "print(\"---------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format(val, pos):\n",
    "    if val == 0:\n",
    "        return \"BULL\"\n",
    "    if val == 1:\n",
    "        return \"BEAR\"\n",
    "    else:\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(real, imputed):\n",
    "    fig, ax = plt.subplots(figsize=(20,4))\n",
    "    ax.xaxis.set_major_locator(plt.MaxNLocator(50))\n",
    "    ax.plot(real.index, real, '-', label=\"Real Data\", color='blue')\n",
    "    ax.plot(real.index, imputed, '-', label=\"Imputed Data\", color='red')\n",
    "    ax.legend(['Real Data', 'Predicted Data'])\n",
    "    ax.yaxis.set_major_locator(plt.MaxNLocator(3))\n",
    "    ax.yaxis.set_major_formatter(plt.FuncFormatter(format))\n",
    "    ax.set_ylim(-0.1, 1.1)\n",
    "    fig.autofmt_xdate()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment_multiple_times(best_params, n=30):\n",
    "    result_dict = {}\n",
    "    result_dict= {'f1':0, 'tn':0, 'fp':0, 'fn':0, 'tp':0, 'auc':0, 'best_f1':0, 'best_model':None, 'best_f1':0, 'best_tn':0, 'best_fp':0, 'best_fn':0, 'best_tp':0}\n",
    "\n",
    "\n",
    "    y = pd.read_csv('input/\\sp500_target_regimes.csv', parse_dates=True)\n",
    "    y.index = y['date'].values\n",
    "    y = y[['regime']]\n",
    "    y = y['regime']=='BEAR'\n",
    "    y = pd.DataFrame (y, columns = ['regime'])\n",
    "\n",
    "    y_train = y.loc['2000-01-01':'2015-01-01']\n",
    "    y_test = y.loc['2015-01-02':]\n",
    "\n",
    "    for i in range(0,n):\n",
    "        X_train = read_csv('output/\\CompleteIndexesWeeklyTrainDecompKalman_'+str(i)+'.csv')\n",
    "        X_test = read_csv('output/\\CompleteIndexesWeeklyTestDecompKalman_'+str(i)+'.csv')['2015-01-02':'2020-03-13']\n",
    "        balance = np.sqrt(len(y_train[y_train['regime']==False])/len(y_train[y_train['regime']==True]))\n",
    "        xgb_model = xgb.XGBClassifier(objective=\"binary:logistic\",\n",
    "                                          learning_rate=best_params['learning_rate'], \n",
    "                                          n_estimators=best_params['n_estimators'], \n",
    "                                          min_child_weight=best_params['min_child_weight'], \n",
    "                                          gamma=best_params['gamma'],\n",
    "                                          max_delta_step=best_params['max_delta_step'],\n",
    "                                          max_depth=best_params['max_depth'],\n",
    "                                          subsample=best_params['subsample'],\n",
    "                                          scale_pos_weight=best_params['scale_pos_weight'],\n",
    "                                          colsample_bytree=best_params['colsample_bytree'],\n",
    "                                          reg_alpha=best_params['reg_alpha']\n",
    "                                      )\n",
    "\n",
    "        model = xgb_model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "        precision = tp/(tp+fp)\n",
    "        recall = tp/(tp+fn)\n",
    "        f_score = (2*precision*recall/(precision+recall))\n",
    "        print('Round', i, \"f1\", f_score)\n",
    "        result_dict['f1'] += f_score\n",
    "        result_dict['tn'] += tn\n",
    "        result_dict['fp'] += fp\n",
    "        result_dict['fn'] += fn\n",
    "        result_dict['tp'] += tp\n",
    "        if result_dict['best_f1'] < f_score:\n",
    "            result_dict['best_f1'] = f_score\n",
    "            result_dict['best_model'] = model\n",
    "            result_dict['best_tn'] = tn\n",
    "            result_dict['best_fp'] = fp\n",
    "            result_dict['best_fn'] = fn\n",
    "            result_dict['best_tp'] = tp\n",
    "        \n",
    "\n",
    "    #plot bear bull imputed and real\n",
    "    #plot(y_test, y_pred)\n",
    "    # feature importance\n",
    "    #data = pd.DataFrame(data=xgb_model.feature_importances_, index=X_train.columns, columns=[\"score\"]).sort_values(by = \"score\", ascending=False)\n",
    "    #data.plot(kind='barh', title=\"Predicted v. Real\", figsize=(10,10))\n",
    "\n",
    "    result_dict['f1'] = result_dict['f1']/n\n",
    "    result_dict['tn'] = result_dict['tn']/n\n",
    "    result_dict['fp'] = result_dict['fp']/n\n",
    "    result_dict['fn'] = result_dict['fn']/n\n",
    "    result_dict['tp'] = result_dict['tp']/n\n",
    "        \n",
    "    return result_dict     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 0 f1 nan\n",
      "Round 1 f1 0.08823529411764706\n",
      "Round 2 f1 nan\n",
      "Round 3 f1 nan\n",
      "Round 4 f1 nan\n",
      "Round 5 f1 nan\n",
      "Round 6 f1 nan\n",
      "Round 7 f1 nan\n",
      "Round 8 f1 nan\n",
      "Round 9 f1 nan\n",
      "Round 10 f1 nan\n",
      "Round 11 f1 nan\n",
      "Round 12 f1 nan\n",
      "Round 13 f1 nan\n",
      "Round 14 f1 nan\n",
      "Round 15 f1 nan\n",
      "Round 16 f1 nan\n",
      "Round 17 f1 0.35443037974683544\n",
      "Round 18 f1 0.2857142857142857\n",
      "Round 19 f1 nan\n",
      "Round 20 f1 0.2857142857142857\n",
      "Round 21 f1 0.35922330097087374\n",
      "Round 22 f1 0.2857142857142857\n",
      "Round 23 f1 nan\n",
      "Round 24 f1 nan\n",
      "Round 25 f1 nan\n",
      "Round 26 f1 nan\n",
      "Round 27 f1 nan\n",
      "Round 28 f1 nan\n",
      "Round 29 f1 nan\n"
     ]
    }
   ],
   "source": [
    "result_dict = run_experiment_multiple_times(best_params, n=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f1': nan,\n",
       " 'tn': 193.23333333333332,\n",
       " 'fp': 13.766666666666667,\n",
       " 'fn': 60.4,\n",
       " 'tp': 4.6,\n",
       " 'auc': 0,\n",
       " 'best_f1': 0.35922330097087374,\n",
       " 'best_model': XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "               colsample_bynode=1, colsample_bytree=0.8, gamma=5, gpu_id=-1,\n",
       "               importance_type='gain', interaction_constraints='',\n",
       "               learning_rate=0.0001, max_delta_step=1, max_depth=1,\n",
       "               min_child_weight=2, missing=nan, monotone_constraints='()',\n",
       "               n_estimators=65, n_jobs=0, num_parallel_tree=1, random_state=0,\n",
       "               reg_alpha=1e-05, reg_lambda=1, scale_pos_weight=5, subsample=0.8,\n",
       "               tree_method='exact', validate_parameters=1, verbosity=None),\n",
       " 'best_tn': 103,\n",
       " 'best_fp': 104,\n",
       " 'best_fn': 28,\n",
       " 'best_tp': 37}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average F1 Score nan\n",
      "     True False\n",
      "True    4.6    13.766666666666667\n",
      "False   60.4    193.23333333333332\n",
      "_______________________________________\n",
      "---------------------------------------\n",
      "_______________________________________________________________________________\n",
      "Best F1 Score 0.35922330097087374\n",
      "     True False\n",
      "True    37    104\n",
      "False   28    103\n",
      "_______________________________________\n",
      "---------------------------------------\n",
      "_______________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "print(\"Average F1 Score\", result_dict['f1'])\n",
    "print_confusion_matrix(result_dict['tn'], result_dict['fp'], result_dict['fn'], result_dict['tp'])\n",
    "print(\"_______________________________________________________________________________\")\n",
    "print(\"Best F1 Score\", result_dict['best_f1'])\n",
    "print_confusion_matrix(result_dict['best_tn'], result_dict['best_fp'], result_dict['best_fn'], result_dict['best_tp'])\n",
    "print(\"_______________________________________________________________________________\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
