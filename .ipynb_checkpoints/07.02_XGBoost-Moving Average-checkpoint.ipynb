{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(file):\n",
    "    df = pd.read_csv(file, parse_dates=True, index_col=0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_confusion_matrix(tn, fp, fn, tp):\n",
    "    print(\"    \",\"True\", \"False\")\n",
    "    print(\"True \", \" \", tp, \"  \", fp)\n",
    "    print(\"False\", \" \",fn,\"  \", tn)\n",
    "    print(\"_______________________________________\")\n",
    "    print(\"---------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format(val, pos):\n",
    "    if val == 0:\n",
    "        return \"BULL\"\n",
    "    if val == 1:\n",
    "        return \"BEAR\"\n",
    "    else:\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(real, imputed):\n",
    "    fig, ax = plt.subplots(figsize=(20,4))\n",
    "    ax.xaxis.set_major_locator(plt.MaxNLocator(50))\n",
    "    ax.plot(real.index, real, '-', label=\"Real Data\", color='blue')\n",
    "    ax.plot(real.index, imputed, '-', label=\"Imputed Data\", color='red')\n",
    "    ax.legend(['Real Data', 'Predicted Data'])\n",
    "    ax.yaxis.set_major_locator(plt.MaxNLocator(3))\n",
    "    ax.yaxis.set_major_formatter(plt.FuncFormatter(format))\n",
    "    ax.set_ylim(-0.1, 1.1)\n",
    "    fig.autofmt_xdate()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost for Moving Average imputed dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = {\n",
    "    'colsample_bytree': 0.3, \n",
    "    'gamma': 0, \n",
    "    'learning_rate': 0.1,\n",
    "    'max_delta_step': 3, \n",
    "    'max_depth': 1, \n",
    "    'min_child_weight': 5, \n",
    "    'n_estimators': 400, \n",
    "    'reg_alpha': 0.1, \n",
    "    'scale_pos_weight': 100, \n",
    "    'subsample': 0.5}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_______________________________________\n",
      "______________Training_________________\n",
      "F1 score 0.9802371541501977\n",
      "     True False\n",
      "True    372    15\n",
      "False   0    395\n",
      "_______________________________________\n",
      "---------------------------------------\n",
      "_______________Testing_________________\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "DataFrame.dtypes for data must be int, float or bool.\n                Did not expect the data types in fields sp500_Close, sp500_Volume, vix_Close, vix_Volume, dji_Close, dji_Volume, ndx_Close, ndx_Volume, n225_Close, n225_Volume, ftse_Close, ftse_Volume, hsi_Close, hsi_Volume, n100_Close, n100_Volume, Overall EMV Tracker, infectious_daily_infect_emv_index, GPR, trade_US Trade Policy Uncertainty, trade_Japanese Trade Policy Uncertainty, trade_Trade Policy EMV Fraction",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-2da154db2581>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[0mprint_confusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"_______________Testing_________________\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m \u001b[0mtn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[0mprecision\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtp\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtp\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\mestrado\\lib\\site-packages\\xgboost\\sklearn.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, data, output_margin, ntree_limit, validate_features, base_margin)\u001b[0m\n\u001b[0;32m    879\u001b[0m         \"\"\"\n\u001b[0;32m    880\u001b[0m         test_dmatrix = DMatrix(data, base_margin=base_margin,\n\u001b[1;32m--> 881\u001b[1;33m                                missing=self.missing, nthread=self.n_jobs)\n\u001b[0m\u001b[0;32m    882\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mntree_limit\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    883\u001b[0m             \u001b[0mntree_limit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"best_ntree_limit\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\mestrado\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, label, weight, base_margin, missing, silent, feature_names, feature_types, nthread)\u001b[0m\n\u001b[0;32m    518\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    519\u001b[0m         data, feature_names, feature_types = _convert_dataframes(\n\u001b[1;32m--> 520\u001b[1;33m             \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_types\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    521\u001b[0m         )\n\u001b[0;32m    522\u001b[0m         \u001b[0mmissing\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmissing\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mmissing\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\mestrado\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36m_convert_dataframes\u001b[1;34m(data, feature_names, feature_types, meta, meta_type)\u001b[0m\n\u001b[0;32m    418\u001b[0m                                                             \u001b[0mfeature_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    419\u001b[0m                                                             \u001b[0mmeta\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 420\u001b[1;33m                                                             meta_type)\n\u001b[0m\u001b[0;32m    421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    422\u001b[0m     data, feature_names, feature_types = _maybe_dt_data(data,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\mestrado\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36m_maybe_pandas_data\u001b[1;34m(data, feature_names, feature_types, meta, meta_type)\u001b[0m\n\u001b[0;32m    292\u001b[0m         msg = \"\"\"DataFrame.dtypes for data must be int, float or bool.\n\u001b[0;32m    293\u001b[0m                 Did not expect the data types in fields \"\"\"\n\u001b[1;32m--> 294\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m', '\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbad_fields\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    295\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    296\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfeature_names\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mmeta\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: DataFrame.dtypes for data must be int, float or bool.\n                Did not expect the data types in fields sp500_Close, sp500_Volume, vix_Close, vix_Volume, dji_Close, dji_Volume, ndx_Close, ndx_Volume, n225_Close, n225_Volume, ftse_Close, ftse_Volume, hsi_Close, hsi_Volume, n100_Close, n100_Volume, Overall EMV Tracker, infectious_daily_infect_emv_index, GPR, trade_US Trade Policy Uncertainty, trade_Japanese Trade Policy Uncertainty, trade_Trade Policy EMV Fraction"
     ]
    }
   ],
   "source": [
    "X_train = read_csv('output/\\MovingAverageWeeklyImputed_training.csv')\n",
    "X_test = read_csv('output/\\MovingAverageWeeklyImputed_test.csv')\n",
    "X_test = X_test.loc['2015-01-02':'2020-03-13']\n",
    "y = pd.read_csv('input/\\sp500_target_regimes.csv', parse_dates=True)\n",
    "y.index = y['date'].values\n",
    "y = y[['regime']]\n",
    "y = y['regime']=='BEAR'\n",
    "y = pd.DataFrame (y, columns = ['regime'])\n",
    "\n",
    "y_train = y.loc['2000-01-01':'2015-01-01']\n",
    "y_test = y.loc['2015-01-02':]\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(objective=\"binary:logistic\",\n",
    "                                  eval_metric = 'auc',\n",
    "                                  learning_rate=best_params['learning_rate'], \n",
    "                                  n_estimators=best_params['n_estimators'], \n",
    "                                  min_child_weight=best_params['min_child_weight'], \n",
    "                                  gamma=best_params['gamma'],\n",
    "                                  max_delta_step=best_params['max_delta_step'],\n",
    "                                  max_depth=best_params['max_depth'],\n",
    "                                  subsample=best_params['subsample'],\n",
    "                                  scale_pos_weight=best_params['scale_pos_weight'],\n",
    "                                  colsample_bytree=best_params['colsample_bytree'],\n",
    "                                  reg_alpha=best_params['reg_alpha']\n",
    "                              )\n",
    "\n",
    "model = xgb_model.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = model.predict(X_train)\n",
    "print(\"_______________________________________\")\n",
    "print(\"______________Training_________________\")\n",
    "tn, fp, fn, tp = confusion_matrix(y_train, y_train_pred).ravel()\n",
    "precision = tp/(tp+fp)\n",
    "recall = tp/(tp+fn)\n",
    "f_score = 2*precision*recall/(precision+recall)  \n",
    "print(\"F1 score\", f_score)\n",
    "print_confusion_matrix(tn, fp, fn, tp)\n",
    "print(\"_______________Testing_________________\")\n",
    "y_pred = model.predict(X_test)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "precision = tp/(tp+fp)\n",
    "recall = tp/(tp+fn)\n",
    "f_score = 2*precision*recall/(precision+recall)\n",
    "print(\"F1 score\", f_score)\n",
    "print_confusion_matrix(tn, fp, fn, tp)\n",
    "print(\"---------------------------------------\")\n",
    "\n",
    "#plot bear bull imputed and real\n",
    "plot(y_test, y_pred)\n",
    "# feature importance\n",
    "data = pd.DataFrame(data=xgb_model.feature_importances_, index=X_train.columns, columns=[\"score\"]).sort_values(by = \"score\", ascending=False)\n",
    "data.plot(kind='barh', title=\"Predicted v. Real\", figsize=(10,10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sp500_Close</th>\n",
       "      <th>sp500_Volume</th>\n",
       "      <th>vix_Close</th>\n",
       "      <th>vix_Volume</th>\n",
       "      <th>dji_Close</th>\n",
       "      <th>dji_Volume</th>\n",
       "      <th>ndx_Close</th>\n",
       "      <th>ndx_Volume</th>\n",
       "      <th>n225_Close</th>\n",
       "      <th>n225_Volume</th>\n",
       "      <th>...</th>\n",
       "      <th>hsi_Close</th>\n",
       "      <th>hsi_Volume</th>\n",
       "      <th>n100_Close</th>\n",
       "      <th>n100_Volume</th>\n",
       "      <th>Overall EMV Tracker</th>\n",
       "      <th>infectious_daily_infect_emv_index</th>\n",
       "      <th>GPR</th>\n",
       "      <th>trade_US Trade Policy Uncertainty</th>\n",
       "      <th>trade_Japanese Trade Policy Uncertainty</th>\n",
       "      <th>trade_Trade Policy EMV Fraction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [sp500_Close, sp500_Volume, vix_Close, vix_Volume, dji_Close, dji_Volume, ndx_Close, ndx_Volume, n225_Close, n225_Volume, ftse_Close, ftse_Volume, hsi_Close, hsi_Volume, n100_Close, n100_Volume, Overall EMV Tracker, infectious_daily_infect_emv_index, GPR, trade_US Trade Policy Uncertainty, trade_Japanese Trade Policy Uncertainty, trade_Trade Policy EMV Fraction]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 22 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
